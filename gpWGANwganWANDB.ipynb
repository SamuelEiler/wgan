{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gpWGANwganWANDB.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5552cfd7af604a7fb2146af434108ed3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0e53101573044af39add48fc1d196f9b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dfd91035465a40b29eeec6355a77b421",
              "IPY_MODEL_814cda348d6849c681d5a66fbe1aba39"
            ]
          }
        },
        "0e53101573044af39add48fc1d196f9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dfd91035465a40b29eeec6355a77b421": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_783f6e52470b43d9951ba701ca74c80d",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 250,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_31a9ecca09e942d5b2dbb7c89658e6df"
          }
        },
        "814cda348d6849c681d5a66fbe1aba39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9528738f9e894281ad13c93f36acd996",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/250 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_24d445f889094311806d1555428f3c55"
          }
        },
        "783f6e52470b43d9951ba701ca74c80d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "31a9ecca09e942d5b2dbb7c89658e6df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9528738f9e894281ad13c93f36acd996": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "24d445f889094311806d1555428f3c55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamuelEiler/wgan/blob/main/gpWGANwganWANDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFQp8W5VWaJu",
        "outputId": "3df8217d-dc86-4e1d-8ba4-c1646aaa0136"
      },
      "source": [
        "!pip install wandb -qqq\r\n",
        "!pip install --upgrade wandb\r\n",
        "!wandb login 50457c76bb245c5d932008de50c1858da49aeeba\r\n",
        "import wandb\r\n",
        "#wandb.init(project=\"sWGAN\")\r\n",
        "\r\n",
        "from __future__ import division\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "from torchvision import transforms\r\n",
        "from torch.autograd.variable import Variable\r\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\r\n",
        "\r\n",
        "import plotly.figure_factory as ff\r\n",
        "import torch\r\n",
        "import numpy as np\r\n",
        "import math\r\n",
        "\r\n",
        "\r\n",
        "import seaborn as sns\r\n",
        "import plotly.express as px\r\n",
        "from torch import autograd\r\n",
        "from torch.distributions.normal import Normal\r\n",
        "import torch.nn.functional as F\r\n",
        "from torch import nn\r\n",
        "from torch import Tensor\r\n",
        "from torch.nn import Parameter\r\n",
        "\r\n",
        "sns.set(rc={'figure.figsize':(11, 8)})\r\n",
        "\r\n",
        "import datetime \r\n",
        "from datetime import date\r\n",
        "today = date.today()\r\n",
        "\r\n",
        "import random\r\n",
        "import json as js\r\n",
        "import pickle\r\n",
        "import os\r\n",
        "import tqdm.notebook as tq\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import random\r\n",
        "import plotly.graph_objects as go\r\n",
        "\r\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\r\n",
        "\r\n",
        "random_seed = 29\r\n",
        "\r\n",
        "np.random.seed(random_seed)\r\n",
        "torch.manual_seed(random_seed)\r\n",
        "torch.set_deterministic(True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.9MB 4.2MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102kB 6.3MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 133kB 52.2MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102kB 6.5MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163kB 49.0MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71kB 5.7MB/s \n",
            "\u001b[?25h  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already up-to-date: wandb in /usr/local/lib/python3.6/dist-packages (0.10.13)\n",
            "Requirement already satisfied, skipping upgrade: configparser>=3.8.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.0.1)\n",
            "Requirement already satisfied, skipping upgrade: shortuuid>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: sentry-sdk>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.19.5)\n",
            "Requirement already satisfied, skipping upgrade: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: subprocess32>=3.5.3 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.5.4)\n",
            "Requirement already satisfied, skipping upgrade: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: GitPython>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.1.12)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.12.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: PyYAML in /usr/local/lib/python3.6/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: docker-pycreds>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied, skipping upgrade: watchdog<0.10.5,>=0.8.3 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.10.4)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: promise<3,>=2.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied, skipping upgrade: urllib3>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi in /usr/local/lib/python3.6/dist-packages (from sentry-sdk>=0.4.0->wandb) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: gitdb<5,>=4.0.1 in /usr/local/lib/python3.6/dist-packages (from GitPython>=1.0.0->wandb) (4.0.5)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.12.0->wandb) (51.1.1)\n",
            "Requirement already satisfied, skipping upgrade: pathtools>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from watchdog<0.10.5,>=0.8.3->wandb) (0.1.2)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: smmap<4,>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (3.0.4)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "OFYjJXAr2rly",
        "outputId": "cc069069-f64d-4f2a-900a-d87bf8740862"
      },
      "source": [
        "\"\"\"Model loading/saving\"\"\"\r\n",
        "dataPath = './dataset'  \r\n",
        "\r\n",
        "\r\n",
        "trainCounter = 0\r\n",
        "loadVersion = 0\r\n",
        "loadModel = True\r\n",
        "epoch_loaded = 0\r\n",
        "path = './SineGAN/' + str(trainCounter)\r\n",
        "\r\n",
        "loadPath = '/content/models.tar'\r\n",
        "\r\n",
        "\r\n",
        "#loadPath = '/content/SineGAN/0/epoch148.tar'\r\n",
        "\r\n",
        "\r\n",
        "\"\"\"Defining parameters\"\"\"\r\n",
        "noise_features = 3 #frequency, amplitude, shift\r\n",
        "sample_size = 64 * 1 #batch size needed for Data Loader and the noise creator function.\r\n",
        "\r\n",
        "\r\n",
        "#Params for the generator\r\n",
        "hidden_nodes_g = 50\r\n",
        "layers = 1\r\n",
        "tanh_layer = False\r\n",
        "bidir = False\r\n",
        "\r\n",
        "dropout = 0.05\r\n",
        "\r\n",
        "#No. of training rounds per epoch\r\n",
        "D_rounds = 1\r\n",
        "G_rounds = 1\r\n",
        "num_epoch = 250\r\n",
        "#learning_rate = 0.0001 # 0.00005  * 200 #*2 for adam \r\n",
        "lr_decrease_factor = 0.98\r\n",
        "lr_start_factor = 0.1\r\n",
        "lr_g = 0.00001 #* 0.5\r\n",
        "lr_d = 0.001 #* 0.5\r\n",
        "beta1 = 0.0\r\n",
        "beta2 = 0.999\r\n",
        "opt_adam = True #working: adam lr*2 lp3\r\n",
        "opt = ''\r\n",
        "if opt_adam:\r\n",
        "  opt = 'Adam'\r\n",
        "else:\r\n",
        "  opt = 'RMS'\r\n",
        "#learning_rate=0.0002, beta_1=0.5, beta_2=0.9\r\n",
        "\r\n",
        "lipschitz_constraint = 10\r\n",
        "center = 1\r\n",
        "onesided = True\r\n",
        "penalty_weight = 10\r\n",
        "if onesided:\r\n",
        "    clip_fn = lambda x: x.clamp(max=0)\r\n",
        "else:\r\n",
        "    clip_fn = lambda x: x    \r\n",
        "#Params for the Discriminator\r\n",
        "minibatch_layer = 0\r\n",
        "minibatch_normal_init_ = True\r\n",
        "num_cvs = 2\r\n",
        "cv1_out= 5\r\n",
        "cv1_k = 3\r\n",
        "cv1_s = 2\r\n",
        "p1_k = 3\r\n",
        "p1_s = 2\r\n",
        "cv2_out = 10\r\n",
        "cv2_k = 5\r\n",
        "cv2_s = 2\r\n",
        "p2_k = 3\r\n",
        "p2_s = 2\r\n",
        "\r\n",
        "wandb.init(project=\"gpWGAN\", config={\r\n",
        "    'center_gp': center,\r\n",
        "    'dropout': dropout,\r\n",
        "    'random_seed': random_seed,\r\n",
        "    \"lipschitz_constraint\": lipschitz_constraint,\r\n",
        "    \"D_rounds\": D_rounds,\r\n",
        "    \"optim\": opt,\r\n",
        "    'beta1': beta1,\r\n",
        "    'beta2': beta2,\r\n",
        "    'penalty_weight': penalty_weight,\r\n",
        "    'one_side': onesided,\r\n",
        "    'sample_size' : sample_size, \r\n",
        "    'noise_features' : noise_features,\r\n",
        "    'seq_length' : 50,\r\n",
        "    'num_layers': layers, \r\n",
        "    'bidir': bidir,\r\n",
        "    'hidden-initialization': 'zeros',\r\n",
        "    'hidden_dims_generator': hidden_nodes_g, \r\n",
        "    'minibatch_layer': minibatch_layer,\r\n",
        "    'minibatch_normal_init_' : minibatch_normal_init_,\r\n",
        "    'num_cvs':num_cvs,\r\n",
        "    'cv1_out':cv1_out,\r\n",
        "    'cv1_k':cv1_k,\r\n",
        "    'cv1_s':cv1_s,\r\n",
        "    'p1_k':p1_k,\r\n",
        "    'p1_s':p1_s,\r\n",
        "    'cv2_out':cv2_out,\r\n",
        "    'cv2_k':cv2_k,\r\n",
        "    'cv2_s':cv2_s,\r\n",
        "    'p2_k':p2_k,\r\n",
        "    'p2_s':p2_s,\r\n",
        "    'num_epoch':num_epoch,\r\n",
        "    'D_rounds': D_rounds,\r\n",
        "    'G_rounds': G_rounds,  \r\n",
        "    'D_lr' : lr_d,\r\n",
        "    'G_lr' : lr_g,\r\n",
        "    'lr_decrease_factor': lr_decrease_factor,\r\n",
        "    'lr_start_factor': lr_start_factor\r\n",
        "\r\n",
        "\r\n",
        "})\r\n",
        "config = wandb.config\r\n",
        "\r\n",
        "\r\n",
        "lr_g = lr_g * lr_start_factor\r\n",
        "lr_d = lr_d * lr_start_factor"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msamueleiler\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.13<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">amber-puddle-8</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/samueleiler/gpWGAN\" target=\"_blank\">https://wandb.ai/samueleiler/gpWGAN</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/samueleiler/gpWGAN/runs/1syal5ds\" target=\"_blank\">https://wandb.ai/samueleiler/gpWGAN/runs/1syal5ds</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210114_075805-1syal5ds</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9HeajX2fbH-"
      },
      "source": [
        "ecg = 0\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "if ecg:\r\n",
        "\r\n",
        "  from google.colab import drive\r\n",
        "  drive.mount('/content/drive')\r\n",
        "\r\n",
        "  !pip install arff2pandas\r\n",
        "\r\n",
        "  from arff2pandas import a2p\r\n",
        "\r\n",
        "  path = '/content/drive/MyDrive/MasterThesis/ECG_Dataset/ECG5000/'\r\n",
        "  with open(path+'ECG5000_TRAIN.arff') as f:\r\n",
        "    train = a2p.load(f)\r\n",
        "  with open(path+'ECG5000_TEST.arff') as f:\r\n",
        "    test = a2p.load(f)\r\n",
        "\r\n",
        "  df = train.append(test)\r\n",
        "  df = df.sample(frac=1.0)\r\n",
        "  df.shape\r\n",
        "\r\n",
        "  CLASS_NORMAL = 1\r\n",
        "  class_names = ['Normal','R on T','PVC','SP','UB']\r\n",
        "\r\n",
        "  new_columns = list(df.columns)\r\n",
        "  new_columns[-1] = 'target'\r\n",
        "  df.columns = new_columns\r\n",
        "\r\n",
        "  df.target.value_counts()\r\n",
        "\r\n",
        "  normal_df = df[df.target == str(CLASS_NORMAL)].drop(labels='target', axis=1)\r\n",
        "  print(normal_df.shape)\r\n",
        "\r\n",
        "  anomaly_df = df[df.target != str(CLASS_NORMAL)].drop(labels='target', axis=1)\r\n",
        "  print(anomaly_df.shape)\r\n",
        "\r\n",
        "  from sklearn.model_selection import train_test_split\r\n",
        "  RANDOM_SEED = 29\r\n",
        "  np.random.seed(RANDOM_SEED)\r\n",
        "  torch.manual_seed(RANDOM_SEED)\r\n",
        "\r\n",
        "\r\n",
        "  train_df, val_df = train_test_split(\r\n",
        "    normal_df,\r\n",
        "    test_size=0.15,\r\n",
        "    random_state=RANDOM_SEED\r\n",
        "  )\r\n",
        "\r\n",
        "  data = pd.DataFrame(train_df[1:][:])  \r\n",
        "\r\n",
        "  dataPath = './dataset'  \r\n",
        "  if not os.path.exists(dataPath):\r\n",
        "    os.makedirs(dataPath)\r\n",
        "\r\n",
        "  data.to_csv(dataPath + '/ecg_data_v1.csv', header = False, index = False)\r\n",
        "\r\n",
        "\r\n",
        "  val_df, test_df = train_test_split(\r\n",
        "    val_df,\r\n",
        "    test_size=0.33,\r\n",
        "    random_state=RANDOM_SEED\r\n",
        "  )\r\n",
        "\r\n",
        "  def create_dataset(df):\r\n",
        "    sequences = df.astype(np.float32).to_numpy().tolist()\r\n",
        "    dataset = [torch.tensor(s).unsqueeze(1).float() for s in sequences]\r\n",
        "    n_seq, seq_len, n_features = torch.stack(dataset).shape\r\n",
        "    return dataset, seq_len, n_features\r\n",
        "\r\n",
        "\r\n",
        "  train_dataset, seq_len, n_features = create_dataset(train_df)\r\n",
        "  val_dataset, _, _ = create_dataset(val_df)\r\n",
        "  test_normal_dataset, _, _ = create_dataset(test_df)\r\n",
        "  test_anomaly_dataset, _, _ = create_dataset(anomaly_df)\r\n",
        "\r\n",
        "  import torch\r\n",
        "  from torch.utils.data import Dataset, DataLoader\r\n",
        "  import pandas as pd\r\n",
        "\r\n",
        "  device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\r\n",
        "\r\n",
        "  class ECGData(Dataset):\r\n",
        "    #This is the class for teh ECG Data that we need to load, transform and then use in teh dataloader.\r\n",
        "    def __init__(self,source_file,transform = None):\r\n",
        "      self.source_file = source_file\r\n",
        "      self.data  = pd.read_csv(source_file, header = None)\r\n",
        "      self.transform = transform\r\n",
        "      \r\n",
        "    def __len__(self):\r\n",
        "      return self.data.shape[0]\r\n",
        "      \r\n",
        "    def __getitem__(self,idx):\r\n",
        "      \r\n",
        "      sample = self.data.iloc[idx]\r\n",
        "      \r\n",
        "      if self.transform:\r\n",
        "          sample = self.transform(sample)\r\n",
        "          \r\n",
        "      return sample   \r\n",
        "\r\n",
        "  \"\"\"Including the function that will transform the dataframe to a pytorch tensor\"\"\"\r\n",
        "  class PD_to_Tensor(object):\r\n",
        "      def __call__(self,sample):\r\n",
        "        return torch.tensor(sample.values).to(device=device, dtype=float)\r\n",
        "\r\n",
        "\r\n",
        "  print(len(train_dataset))\r\n",
        "  print(seq_len)\r\n",
        "  print(n_features)\r\n",
        "  for n in range(10):\r\n",
        "    plt.plot(train_dataset[n])\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "  def GetECGData(source_file):\r\n",
        "    compose = transforms.Compose([PD_to_Tensor()])\r\n",
        "    return ECGData(source_file ,transform = compose)\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUrjR5i_7d0w"
      },
      "source": [
        "### Kaggle and imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuPy-NTY7d0z",
        "scrolled": false
      },
      "source": [
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpIwLbfn7d04"
      },
      "source": [
        "### Models (Generator and Discriminator)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dy8DFFaO7d05",
        "scrolled": false
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class MinibatchDiscrimination(torch.nn.Module):\n",
        "   def __init__(self,input_features,output_features,minibatch_normal_init, hidden_features=16):\n",
        "      super(MinibatchDiscrimination,self).__init__()\n",
        "      \n",
        "      self.input_features = input_features\n",
        "      self.output_features = output_features\n",
        "      self.hidden_features = hidden_features\n",
        "      self.T = torch.nn.Parameter(torch.randn(self.input_features,self.output_features, self.hidden_features))\n",
        "      if minibatch_normal_init == True:\n",
        "        nn.init.normal_(self.T, 0,1)\n",
        "      \n",
        "   def forward(self,x):\n",
        "      M = torch.mm(x,self.T.view(self.input_features,-1))\n",
        "      M = M.view(-1, self.output_features, self.hidden_features).unsqueeze(0)\n",
        "      M_t = M.permute(1, 0, 2, 3)\n",
        "      # Broadcasting reduces the matrix subtraction to the form desired in the paper\n",
        "      out = torch.sum(torch.exp(-(torch.abs(M - M_t).sum(3))), dim=0) - 1\n",
        "      \n",
        "      return torch.cat([x, out], 1)\n",
        "    \n",
        "\n",
        "# Use minibatch = 0 for no minibatch discriminiation layer to be used in the architecture. If minibatch > 0, then minibatch is the number of output dimensions of the MBD layer.\n",
        "class Discriminator(torch.nn.Module):\n",
        "  def __init__(self,seq_length,batch_size,minibatch_normal_init, n_features = 1, num_cv = 1, minibatch = 0, cv1_out= 10, cv1_k = 3, cv1_s = 4, p1_k = 3, p1_s = 3, cv2_out = 10, cv2_k = 3, cv2_s = 3 ,p2_k = 3, p2_s = 3):\n",
        "      super(Discriminator,self).__init__()\n",
        "      self.n_features = n_features\n",
        "      self.seq_length = seq_length\n",
        "      self.batch_size = batch_size\n",
        "      self.num_cv = num_cv\n",
        "      self.minibatch = minibatch\n",
        "      self.cv1_dims = int((((((seq_length - cv1_k)/cv1_s) + 1)-p1_k)/p1_s)+1)\n",
        "      self.cv2_dims = int((((((self.cv1_dims - cv2_k)/cv2_s) + 1)-p2_k)/p2_s)+1)\n",
        "      self.cv1_out = cv1_out\n",
        "      self.cv2_out = cv2_out\n",
        "\n",
        "\n",
        "      #self.dropout = torch.nn.Dropout(0.05)\n",
        "\n",
        "      \n",
        "      #input should be size (batch_size,num_features,seq_length) for the convolution layer\n",
        "      self.CV1 = torch.nn.Sequential(\n",
        "                  torch.nn.Conv1d(in_channels = self.n_features, out_channels = int(cv1_out),kernel_size = int(cv1_k), stride = int(cv1_s), padding=0)\n",
        "                  #,nn.InstanceNorm1d(int(cv1_out), affine=True)\n",
        "\n",
        "                  ,torch.nn.LeakyReLU()        \n",
        "                  ,torch.nn.AvgPool1d(kernel_size = int(p1_k), stride = int(p1_s))   \n",
        "                 )\n",
        "      \n",
        "      # 2 convolutional layers\n",
        "      if self.num_cv > 1:\n",
        "        self.CV2 = torch.nn.Sequential(\n",
        "                      torch.nn.Conv1d(in_channels = int(cv1_out), out_channels = int(cv2_out) ,kernel_size =int(cv2_k), stride = int(cv2_s), padding=0)\n",
        "                      #,nn.InstanceNorm1d(int(cv2_out), affine=True)\n",
        "\n",
        "                      ,torch.nn.LeakyReLU()\n",
        "                      ,torch.nn.AvgPool1d(kernel_size = int(p2_k), stride = int(p2_s))\n",
        "                  )\n",
        "        \n",
        "        #Adding a minibatch discriminator layer to add a cripple affect to the discriminator so that it needs to generate sequences that are different from each other.\n",
        "        \n",
        "        if   self.minibatch > 0:\n",
        "          self.mb1 = MinibatchDiscrimination(self.cv2_dims*cv2_out,self.minibatch, minibatch_normal_init)\n",
        "          self.out = torch.nn.Sequential(torch.nn.Linear(int(self.cv2_dims*cv2_out)+self.minibatch,1),torch.nn.Sigmoid()) # to make sure the output is between 0 and 1\n",
        "        else:\n",
        "          self.out = torch.nn.Sequential(torch.nn.Linear(int(self.cv2_dims*cv2_out),1)) # to make sure the output is between 0 and 1 \n",
        "      \n",
        "      # 1 convolutional layer\n",
        "      else:\n",
        "        #Adding a minibatch discriminator layer to add a cripple affect to the discriminator so that it needs to generate sequences that are different from each other.\n",
        "        if self.minibatch > 0 :    \n",
        "          self.mb1 = MinibatchDiscrimination(int(self.cv1_dims*cv1_out),self.minibatch, minibatch_normal_init)\n",
        "          self.out = torch.nn.Sequential(torch.nn.Linear(int(self.cv1_dims*cv1_out)+self.minibatch,1),torch.nn.Dropout(0.2)) # to make sure the output is between 0 and 1\n",
        "        else:\n",
        "          self.out = torch.nn.Sequential(torch.nn.Linear(int(self.cv1_dims*cv1_out),1))  \n",
        "      \n",
        "      \n",
        "\n",
        "  def forward(self,x):\n",
        "      self.batch_size = x.size(0)\n",
        "      x = self.CV1(x.view(self.batch_size,1,self.seq_length))\n",
        "      # conv 1  -> conv2 -> dropout -> linear\n",
        "      #2 Convolutional Layers\n",
        "      if self.num_cv > 1:   \n",
        "        x = self.CV2(x)\n",
        "        #x = self.dropout(x)\n",
        "        x = x.view(self.batch_size,-1)\n",
        "        \n",
        "        #2 CNN with minibatch discrimination\n",
        "        if self.minibatch > 0:\n",
        "             x = self.mb1(x.squeeze())\n",
        "             x = self.out(x.squeeze())\n",
        "             \n",
        "        #2 CNN and no minibatch discrimination\n",
        "        else:\n",
        "             x = self.out(x.squeeze())\n",
        "        \n",
        "      # 1 Convolutional Layer\n",
        "      else: \n",
        "        x = x.view(self.batch_size,-1)\n",
        "       \n",
        "        #1 convolutional Layer and minibatch discrimination\n",
        "        if self.minibatch > 0:\n",
        "             x = self.mb1(x)\n",
        "             x = self.out(x)\n",
        "        \n",
        "        #1 convolutional Layer and no minibatch discrimination\n",
        "        else:\n",
        "             x = self.out(x)    \n",
        "      return x\n",
        "  \n",
        "\n",
        "\n",
        "class Generator(torch.nn.Module):\n",
        "  #seq_length not important\n",
        "  def __init__(self,seq_length,batch_size,n_features = 1, hidden_dim = 50, num_layers = 2, tanh_output = False, bidirectional = False):\n",
        "      super(Generator,self).__init__()\n",
        "      self.n_features = n_features\n",
        "      self.hidden_dim = hidden_dim\n",
        "      self.num_layers = num_layers\n",
        "      self.seq_length = seq_length\n",
        "      self.batch_size = batch_size\n",
        "      self.tanh_output = tanh_output\n",
        "      self.bidirectional = bidirectional\n",
        "\n",
        "      #self.dropout = torch.nn.Dropout(0.05)\n",
        "\n",
        "      \n",
        "      #Checking if the architecture uses a BiLSTM and setting the output parameters as appropriate.\n",
        "      if self.bidirectional == True:\n",
        "        self.num_dirs = 2\n",
        "      else:\n",
        "        self.num_dirs = 1\n",
        "      \n",
        "      \n",
        "      self.layer1 = torch.nn.LSTM(input_size = self.n_features, hidden_size = self.hidden_dim, num_layers = self.num_layers,batch_first = True, bidirectional = self.bidirectional )\n",
        "      self.out = torch.nn.Linear(self.hidden_dim,1) # to make sure the output is between 0 and 1 - removed ,torch.nn.Sigmoid()\n",
        "  \n",
        "  def forward(self,x):\n",
        "      self.seq_length = x.size(1)\n",
        "      self.batch_size = x.size(0)\n",
        "\n",
        "      h_0 = torch.zeros(self.num_layers*self.num_dirs, self.batch_size, self.hidden_dim, requires_grad=True).to(device)\n",
        "      c_0 = torch.zeros(self.num_layers*self.num_dirs, self.batch_size, self.hidden_dim, requires_grad=True).to(device)\n",
        "      #x, _ = self.layer1(x.view(self.batch_size,self.seq_length,1), (h_0, c_0)) \n",
        "      x, _ = self.layer1(x.view(self.batch_size,self.seq_length, noise_features), (h_0, c_0)) #--------------------------------noise_features ---------------------------------------\n",
        "\n",
        "\n",
        "      if self.bidirectional == True:\n",
        "        x = x.view(x.size(0), x.size(1), 2, -1).sum(2).view(x.size(0), x.size(1), -1)\n",
        "      \n",
        "      #Note that the output of the bidirectional LSTM is in the form (batch_size,seq_lenth,num_dirs*hidden_dim) To separate the directions, we can use \n",
        "      #x.view(self.batch_size,self.seq_length,self.num_dirs, self.hidden_dim)\n",
        "      #x = self.dropout(x)\n",
        "\n",
        "      x = self.out(x)\n",
        "\n",
        "      return x.squeeze() #,hidden "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krloNMoT7d09"
      },
      "source": [
        "### Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onF_Ajx-7d0-",
        "scrolled": false
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class SineData(Dataset):\n",
        "  #This is the class for teh ECG Data that we need to load, transform and then use in teh dataloader.\n",
        "  def __init__(self,source_file,transform = None):\n",
        "    self.source_file = source_file\n",
        "    self.data  = pd.read_csv(source_file, header = None)\n",
        "    self.transform = transform\n",
        "    \n",
        "  def __len__(self):\n",
        "    return self.data.shape[0]\n",
        "    \n",
        "  def __getitem__(self,idx):\n",
        "    \n",
        "    sample = self.data.iloc[idx]\n",
        "    \n",
        "    if self.transform:\n",
        "        sample = self.transform(sample)\n",
        "        \n",
        "    return sample   \n",
        "\n",
        "\"\"\"Including the function that will transform the dataframe to a pytorch tensor\"\"\"\n",
        "class PD_to_Tensor(object):\n",
        "    def __call__(self,sample):\n",
        "      return torch.tensor(sample.values).to(device=device, dtype=float)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLzzVg_k7d1B"
      },
      "source": [
        "### Create Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKWu839c7d1C",
        "scrolled": false
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "\n",
        "dataPath = './dataset'  \n",
        "if not os.path.exists(dataPath):\n",
        "        os.makedirs(dataPath)\n",
        "\n",
        "trainingset_size = 64 * 150\n",
        "testset_size = 64 * 20\n",
        "\n",
        "\"\"\"Create a training set of sine waves with 10000 records\"\"\"\n",
        "\n",
        "#a = np.arange(0.1,0.9,0.02)\n",
        "x = np.arange(0,20,0.4)\n",
        "#r = np.arange(2,6.1,0.1)\n",
        "count = 0\n",
        "fs = len(x)\n",
        "y = np.zeros((1,len(x)))\n",
        "\n",
        "for n in range(trainingset_size):\n",
        "  amp = random.uniform(0.1, 0.9)\n",
        "  rad = random.uniform(5, 10)\n",
        "  phase = random.uniform(-fs/0.5*np.pi,fs/0.5*np.pi)\n",
        "  offsetY = 0 #random.uniform(-1, 1)\n",
        "  y = np.append(y,  offsetY + amp*np.sin(((2*np.pi*rad*x)+phase)/fs).reshape((1,len(x))),axis = 0)\n",
        "  \n",
        "# for n in range(20):\n",
        "#    plt.plot(y[n + 1])\n",
        "# plt.show()\n",
        "data = pd.DataFrame(y[1:][:])  \n",
        "data.to_csv(dataPath + '/sinedata_v2.csv', header = False, index = False)\n",
        "\n",
        "\"\"\"Creating a test set of sine waves with 3000 records\"\"\"\n",
        "a = np.arange(0.1,0.9,0.02)\n",
        "x = np.arange(0,20,0.5)\n",
        "r = np.arange(2,6.1,0.1)\n",
        "count = 0\n",
        "fs = len(x)\n",
        "y = np.zeros((1,len(x)))\n",
        "\n",
        "for n in range(testset_size):\n",
        "  amp = a[random.randint(0,len(a)-1)]\n",
        "  rad = r[random.randint(0,len(r)-1)]\n",
        "  phase = random.uniform(-1,1)*np.pi\n",
        "\n",
        "  y = np.append(y,amp*np.sin(((2*np.pi*rad*x)+phase)/fs).reshape((1,len(x))),axis = 0)\n",
        "  \n",
        "data = pd.DataFrame(y[1:][:])  \n",
        "data.to_csv(dataPath + '/sinedata_test_v2.csv', header = False, index = False)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ak6ADH40auP"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Krranegc7d1F"
      },
      "source": [
        "### Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnxOCeOt7d1F",
        "scrolled": false
      },
      "source": [
        "def noise(batchsize, seq_length, noise_features):\n",
        "    rnoise = torch.ones( (batchsize, seq_length, noise_features)).to(device)\n",
        "    if noise_features == 1:\n",
        "      return torch.rand(batchsize, seq_length, 1)\n",
        "\n",
        "    for b in range(batchsize):\n",
        "        randoms = np.ones(noise_features)\n",
        "        for nf in range(noise_features):\n",
        "            randoms[nf] = random.uniform(-1,1)\n",
        "        for i in range(seq_length):\n",
        "            for nf in range(noise_features):\n",
        "                rnoise[b][i][nf] = randoms[nf]\n",
        "    return rnoise\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def pdist(sample_1, sample_2, norm=2, eps=1e-5):\n",
        "    n_1, n_2 = sample_1.size(0), sample_2.size(0)\n",
        "    norm = float(norm)\n",
        "    \n",
        "    if norm == 2.:\n",
        "        norms_1 = torch.sum(sample_1**2, dim=1, keepdim=True)\n",
        "        norms_2 = torch.sum(sample_2**2, dim=1, keepdim=True)\n",
        "        norms = (norms_1.expand(n_1, n_2) +\n",
        "                 norms_2.transpose(0, 1).expand(n_1, n_2))\n",
        "        distances_squared = norms - 2 * sample_1.mm(sample_2.t())\n",
        "        return torch.sqrt(eps + torch.abs(distances_squared))\n",
        "    else:\n",
        "        dim = sample_1.size(1)\n",
        "        expanded_1 = sample_1.unsqueeze(1).expand(n_1, n_2, dim)\n",
        "        expanded_2 = sample_2.unsqueeze(0).expand(n_1, n_2, dim)\n",
        "        differences = torch.abs(expanded_1 - expanded_2) ** norm\n",
        "        inner = torch.sum(differences, dim=2, keepdim=False)\n",
        "        return (eps + inner) ** (1. / norm)\n",
        "\n",
        "def permutation_test_mat(matrix,n_1,  n_2,  n_permutations, a00=1,  a11=1,  a01=0):\n",
        "    n = n_1 + n_2\n",
        "    pi = np.zeros(n, dtype=np.int8)\n",
        "    pi[n_1:] = 1\n",
        "\n",
        "    larger = 0.\n",
        "    count = 0\n",
        "    \n",
        "    for sample_n in range(1 + n_permutations):\n",
        "        count = 0.\n",
        "        for i in range(n):\n",
        "            for j in range(i, n):\n",
        "                mij = matrix[i, j] + matrix[j, i]\n",
        "                if pi[i] == pi[j] == 0:\n",
        "                    count += a00 * mij\n",
        "                elif pi[i] == pi[j] == 1:\n",
        "                    count += a11 * mij\n",
        "                else:\n",
        "                    count += a01 * mij\n",
        "        if sample_n == 0:\n",
        "            statistic = count\n",
        "        elif statistic <= count:\n",
        "            larger += 1\n",
        "\n",
        "        np.random.shuffle(pi)\n",
        "\n",
        "    return larger / n_permutations\n",
        "\n",
        "\n",
        "class MMDStatistic:\n",
        "    def __init__(self, n_1, n_2):\n",
        "        self.n_1 = n_1\n",
        "        self.n_2 = n_2\n",
        "\n",
        "        # The three constants used in the test.\n",
        "        self.a00 = 1. / (n_1 * (n_1 - 1))\n",
        "        self.a11 = 1. / (n_2 * (n_2 - 1))\n",
        "        self.a01 = - 1. / (n_1 * n_2)\n",
        "\n",
        "    def __call__(self, sample_1, sample_2, alphas, ret_matrix=False):\n",
        "\n",
        "        sample_12 = torch.cat((sample_1, sample_2), 0)\n",
        "        distances = pdist(sample_12, sample_12, norm=2)\n",
        "\n",
        "        kernels = None\n",
        "        for alpha in alphas:\n",
        "            kernels_a = torch.exp(- alpha * distances ** 2)\n",
        "            if kernels is None:\n",
        "                kernels = kernels_a\n",
        "            else:\n",
        "                kernels = kernels + kernels_a\n",
        "\n",
        "        k_1 = kernels[:self.n_1, :self.n_1]\n",
        "        k_2 = kernels[self.n_1:, self.n_1:]\n",
        "        k_12 = kernels[:self.n_1, self.n_1:]\n",
        "\n",
        "        mmd = (2 * self.a01 * k_12.sum() +\n",
        "               self.a00 * (k_1.sum() - torch.trace(k_1)) +\n",
        "               self.a11 * (k_2.sum() - torch.trace(k_2)))\n",
        "        if ret_matrix:\n",
        "            return mmd, kernels\n",
        "        else:\n",
        "            return mmd\n",
        "\n",
        "\n",
        "    def pval(self, distances, n_permutations=1000):\n",
        "        if isinstance(distances, Variable):\n",
        "            distances = distances.data\n",
        "        return permutation_test_mat(distances.cpu().numpy(),\n",
        "                                    self.n_1, self.n_2,\n",
        "                                    n_permutations,\n",
        "                                    a00=self.a00, a11=self.a11, a01=self.a01)\n",
        "\n",
        "\n",
        "\n",
        "def saveModel(path, epoch): \n",
        "    \n",
        "    torch.save({\n",
        "            'generator_state_dict': generator.state_dict(),\n",
        "            'discriminator_state_dict': discriminator.state_dict(),\n",
        "            'optimizerG_state_dict': generator_opt.state_dict(),\n",
        "            'optimizerD_state_dict': discriminator_opt.state_dict(),  \n",
        "            'D_losses': D_losses,\n",
        "            'G_losses': G_losses,\n",
        "            'mmd_list': mmd_list,\n",
        "            'gradient_p': gradient_p,\n",
        "            'series_list': series_list,\n",
        "            'epoch': epoch\n",
        "            }, path +'/epoch'+str(epoch)+'.tar')\n",
        "\n",
        "\n",
        "def pairwisedistances(X,Y,norm=2):\n",
        "    dist = pdist(X,Y,norm)\n",
        "    return np.median(dist.numpy())\n",
        "\n",
        "\n",
        "def GetSineData(source_file):\n",
        "  compose = transforms.Compose([PD_to_Tensor()])\n",
        "  return SineData(source_file ,transform = compose)\n",
        "\n",
        "def compute_grad2(d_out, x_in):\n",
        "    batch_size = x_in.size(0)\n",
        "    grad_dout = autograd.grad(\n",
        "        outputs=d_out.sum(), inputs=x_in,\n",
        "        create_graph=True, retain_graph=True, only_inputs=True\n",
        "    )[0]\n",
        "    grad_dout2 = grad_dout.pow(2)\n",
        "    assert(grad_dout2.size() == x_in.size())\n",
        "    reg = grad_dout2.view(batch_size, -1).sum(1)\n",
        "    return reg\n",
        "\n",
        "def wgan_gp_reg(discriminator, x_real, x_fake, center=0.):\n",
        "    batch_size = x_fake.size(0)\n",
        "    #x_real = x_real.unsqueeze(1)\n",
        "    #x_fake = x_fake.unsqueeze(1)\n",
        "    #print(f'xrea {x_real.shape}')\n",
        "    #print(f'xfake {x_fake.shape}')\n",
        "    eps = torch.rand(batch_size, device=x_fake.device).view(batch_size, 1)\n",
        "    x_interp = (1 - eps) * x_real + eps * x_fake\n",
        "    x_interp = x_interp.detach()\n",
        "    x_interp.requires_grad_()\n",
        "    #print(f'intr {x_interp.shape}')\n",
        "    d_out = discriminator(x_interp)\n",
        "\n",
        "    reg = ( torch.sqrt(compute_grad2(d_out, x_interp) + 1e-12) - center).pow(2).mean()\n",
        "\n",
        "    #print(f'reg: {reg}')\n",
        "    return reg\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDnOaj5T7d1J"
      },
      "source": [
        "### Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ble1AVAh7d1K",
        "scrolled": false
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5h6Ms-od7d1O"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334,
          "referenced_widgets": [
            "5552cfd7af604a7fb2146af434108ed3",
            "0e53101573044af39add48fc1d196f9b",
            "dfd91035465a40b29eeec6355a77b421",
            "814cda348d6849c681d5a66fbe1aba39",
            "783f6e52470b43d9951ba701ca74c80d",
            "31a9ecca09e942d5b2dbb7c89658e6df",
            "9528738f9e894281ad13c93f36acd996",
            "24d445f889094311806d1555428f3c55"
          ]
        },
        "id": "FVFu3fV77d1P",
        "scrolled": false,
        "outputId": "f73ed10b-65af-4ab8-ec9b-7b0885cc5461"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f'Using : {device}')\n",
        "    print(torch.cuda.get_device_name(device))\n",
        "else :\n",
        "    print(f'Using : {device}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"Creating the training set of sine signals\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "source_filename =  dataPath + '/sinedata_v2.csv'\n",
        "sine_data = GetSineData(source_file = source_filename)\n",
        "data_loader = torch.utils.data.DataLoader(sine_data, batch_size=sample_size, shuffle=True, drop_last=True)\n",
        "seq_length = sine_data[0].size()[0] #Number of features\n",
        "\n",
        "if ecg:\n",
        "  ecg_path =  dataPath + '/ecg_data_v1.csv'\n",
        "  sine_data = GetECGData(source_file = ecg_path)\n",
        "  data_loader = torch.utils.data.DataLoader(sine_data, batch_size=sample_size, shuffle=True)\n",
        "  seq_length = 140\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Num batches\n",
        "num_batches = len(data_loader)\n",
        "\n",
        "\"\"\"Creating the Test Set\"\"\"\n",
        "test_filename = dataPath + '/sinedata_test_v2.csv' #'./sinedata_test_v2.csv'\n",
        "\n",
        "sine_data_test = GetSineData(source_file = test_filename)\n",
        "data_loader_test = torch.utils.data.DataLoader(sine_data_test, batch_size=sample_size, shuffle=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\" Evaluation of GAN with 1 CNN Layer in Discriminator\n",
        "##Generator and Discriminator training phase\n",
        "\"\"\"\n",
        "#minibatch_out = [5] #[0,3,5,8,10]\n",
        "#for minibatch_layer in tq.tqdm(minibatch_out):\n",
        "#path = \"./output/Run_\"+str(today.strftime(\"%d_%m_%Y\"))+\"_\"+ str(datetime.datetime.now().time()).split('.')[0]\n",
        "\n",
        "\n",
        "if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Initialising the generator and discriminator\n",
        "generator = Generator(seq_length,sample_size,n_features = noise_features, hidden_dim =  hidden_nodes_g,num_layers= layers, tanh_output = tanh_layer, bidirectional = bidir).to(device)\n",
        "discriminator = Discriminator(seq_length, sample_size ,minibatch_normal_init = minibatch_normal_init_, minibatch = minibatch_layer,num_cv = num_cvs, cv1_out = cv1_out,cv1_k = cv1_k, cv1_s = cv1_s, p1_k = p1_k, p1_s = p1_s, cv2_out= cv2_out, cv2_k = cv2_k, cv2_s = cv2_s, p2_k = p2_k, p2_s = p2_s).to(device)\n",
        "#Loss function \n",
        "loss_1 = torch.nn.BCELoss()\n",
        "\n",
        "\n",
        "\n",
        "#Defining optimizer\n",
        "if opt_adam:\n",
        "    discriminator_opt = torch.optim.Adam(discriminator.parameters(),lr = lr_d, betas=[beta1, beta2])\n",
        "    generator_opt = torch.optim.Adam(generator.parameters(),lr = lr_g,  betas=[beta1, beta2])\n",
        "else:\n",
        "    discriminator_opt = torch.optim.RMSprop(discriminator.parameters(), lr=learning_rate)\n",
        "    generator_opt = torch.optim.RMSprop(generator.parameters(), lr=learning_rate)\n",
        "\n",
        "gradient_p = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "mmd_list = []\n",
        "series_list = np.zeros((1,seq_length))\n",
        "\n",
        "\n",
        "if loadModel:\n",
        "    checkpoint = torch.load(loadPath)#torch.load(loadPath)\n",
        "    generator.load_state_dict(checkpoint['generator_state_dict'])\n",
        "    discriminator.load_state_dict(checkpoint['discriminator_state_dict'])\n",
        "    generator_opt.load_state_dict(checkpoint['optimizerG_state_dict'])\n",
        "    discriminator_opt.load_state_dict(checkpoint['optimizerD_state_dict'])\n",
        "    gradient_p = checkpoint['gradient_p']\n",
        "    G_losses = checkpoint['G_losses']\n",
        "    D_losses = checkpoint['D_losses']\n",
        "    mmd_list = checkpoint['mmd_list']\n",
        "    series_list = checkpoint['series_list']\n",
        "    epoch_loaded = checkpoint['epoch']\n",
        "    \n",
        "    plt.plot(G_losses)\n",
        "    plt.plot(D_losses)\n",
        "    plt.plot(mmd_list)\n",
        "    plt.plot(gradient_p)\n",
        "    plt.show()\n",
        "    print('Models loaded!')\n",
        "\n",
        "\n",
        "\n",
        "wandb.watch([generator, discriminator], log='all', log_freq=80*1)\n",
        "#wandb.watch(, log='all',  log_freq=80*2)\n",
        "\n",
        "\n",
        "generator.train()\n",
        "discriminator.train()\n",
        "\n",
        "\n",
        "\n",
        "gradient_penalty = torch.ones(1).to(device)\n",
        "\n",
        "\n",
        "input1 = torch.FloatTensor(sample_size, 2).to(device)\n",
        "input2 = torch.FloatTensor(sample_size, 2).to(device)\n",
        "interp_alpha = torch.FloatTensor(sample_size, 1).to(device)\n",
        "\n",
        "fixed_noise = torch.FloatTensor(sample_size, 2).normal_(0, 1).to(device)\n",
        "perturbation = torch.FloatTensor(sample_size,2).to(device)   \n",
        "\n",
        "\n",
        "itera = -1\n",
        "\n",
        "for epoch in tq.tqdm(range(num_epoch)):\n",
        "    if epoch <= epoch_loaded: continue\n",
        "    for n_batch, sample_data in enumerate(data_loader): # enumerate(tq.tqdm(data_loader)): #tq.tqdm(enumerate(data_loader)):     \n",
        "\n",
        "      lr_g = lr_g * lr_decrease_factor\n",
        "      lr_d = lr_d * lr_decrease_factor\n",
        "    \n",
        "      #for d in range(D_rounds):\n",
        "      #Train Discriminator on Fake Data\n",
        "      discriminator.zero_grad()\n",
        "\n",
        "      #Generating the noise and label data\n",
        "      noise_sample = noise(len(sample_data), seq_length,noise_features )\n",
        "\n",
        "      #Use this line if generator outputs hidden states: fake_data, (h_g_n,c_g_n) = generator.forward(noise_sample,h_g)\n",
        "      fake_data = generator(noise_sample).detach()\n",
        "\n",
        "      critic_out_fake = discriminator(fake_data)\n",
        "\n",
        "      real_data = sample_data.requires_grad_().to(device=device, dtype=torch.float)\n",
        "      critic_out_real  = discriminator(real_data)\n",
        "      loss_discriminator = critic_out_fake.mean() - critic_out_real.mean()\n",
        "      \n",
        "      if lipschitz_constraint == 0:\n",
        "          # Calculate interpolation\n",
        "          epsilon = torch.rand(sample_size, 1).to(device)\n",
        "          epsilon = epsilon.expand_as(real_data)\n",
        "          interpolated = epsilon * real_data + (1 - epsilon) * fake_data # interpolates := xhat        \n",
        "          interpolated = Variable(interpolated, requires_grad=True).to(device)\n",
        "          # Calculate probability of interpolated examples\n",
        "          prob_interpolated = discriminator(interpolated)\n",
        "          gradients = torch.autograd.grad(outputs=prob_interpolated, inputs=interpolated, grad_outputs=torch.ones_like(prob_interpolated), create_graph=True, retain_graph=True)[0]\n",
        "          # set up tensors (torch administrativa)\n",
        "          # Gradients have shape (batch_size, num_channels, img_width, img_height),\n",
        "          # so flatten to easily take norm per example in batch\n",
        "          gradients = gradients.view(sample_size, -1)\n",
        "          # Derivatives of the gradient close to 0 can cause problems because of\n",
        "          # the square root, so manually calculate norm and add epsilon\n",
        "          gradients_norm = torch.sqrt(torch.sum(gradients ** 2, dim=1) + 1e-12)\n",
        "          gradient_penalty =penalty_weight * ((gradients_norm - 1) ** 2).mean()        \n",
        "          loss_discriminator = loss_discriminator +   gradient_penalty\n",
        "      \n",
        "      elif lipschitz_constraint == 1:\n",
        "              dist = ((real_data-fake_data)**2).sum(1)**0.5\n",
        "              lip_est = (critic_out_real.mean()-critic_out_fake.mean()).abs()/(dist+1e-8)\n",
        "              lip_loss = penalty_weight*(clip_fn(1.0-lip_est)**2).mean(0).view(1)\n",
        "              gradient_penalty = lip_loss\n",
        "              loss_discriminator = loss_discriminator + lip_loss\n",
        "      elif lipschitz_constraint == 3:           \n",
        "              interp_alpha.resize_(sample_size, 1)\n",
        "              interp_alpha.uniform_()\n",
        "              interp_points = Variable((interp_alpha.expand_as(real_data.data)*real_data.data+(1-interp_alpha.expand_as(real_data.data))*fake_data.data), requires_grad=True)\n",
        "              errD_interp_vec = discriminator(interp_points)\n",
        "              errD_gradient, = torch.autograd.grad(errD_interp_vec.sum(), interp_points, create_graph=True)\n",
        "              lip_est = (errD_gradient**2).view(sample_size,-1).sum(1)**0.5 # updated: bug fix: added **0.5\n",
        "              lip_loss = penalty_weight*(clip_fn(1.0-lip_est)**2).mean(0).view(1)\n",
        "              gradient_penalty = lip_loss\n",
        "              loss_discriminator = loss_discriminator + lip_loss\n",
        "      elif lipschitz_constraint == 4 or lipschitz_constraint == 5:\n",
        "          if lipschitz_constraint == 4:\n",
        "            # this tries to match DRAGAN\n",
        "            perturbation.resize_as_(real_data.data)\n",
        "            perturbation.uniform_()\n",
        "            perturbation *= 0.5*real_data.data.std()\n",
        "            interp_alpha.resize_(sample_size, 1)  \n",
        "            interp_alpha.uniform_()\n",
        "            perturbation *= interp_alpha.expand_as(perturbation)\n",
        "          else:\n",
        "            # the choice of perturbation and leaving out alpha differs from the DRAGAN article\n",
        "            perturbation.resize_as_(real_data.data)\n",
        "            perturbation.normal_()\n",
        "            perturbation *= 0.25*real_data.data.std(0).expand_as(perturbation)\n",
        "\n",
        "\n",
        "          perturbation += real_data.data\n",
        "          interp_points = Variable(perturbation, requires_grad=True)\n",
        "          errD_interp_vec = discriminator(interp_points)\n",
        "          errD_gradient, = torch.autograd.grad(errD_interp_vec.sum(), interp_points, create_graph=True)\n",
        "          lip_est = (errD_gradient**2).view(sample_size,-1).sum(1)**0.5\n",
        "          lip_loss = penalty_weight*(clip_fn(1.0-lip_est)**2).mean(0).view(1)\n",
        "          gradient_penalty = lip_loss\n",
        "          loss_discriminator = loss_discriminator + lip_loss\n",
        "\n",
        "      elif lipschitz_constraint == 10:\n",
        "          gradient_penalty = penalty_weight * wgan_gp_reg(discriminator, real_data, fake_data, center)\n",
        "          loss_discriminator = loss_discriminator +  gradient_penalty\n",
        "          #print(gradient_penalty)\n",
        "      elif lipschitz_constraint == 11:\n",
        "          \n",
        "          for p in discriminator.parameters():\n",
        "            p.data.clamp_(-0.1, 0.1)\n",
        "\n",
        "        \n",
        "      loss_discriminator.backward()\n",
        "\n",
        "      discriminator_opt.step() #Updating the weights based on the predictions for both real and fake calculations.\n",
        "        \n",
        "        \n",
        "    \n",
        "\n",
        "      #Train Generator  \n",
        "      #for g in range(G_rounds):\n",
        "      generator.zero_grad()\n",
        "\n",
        "      #noise_sample = Variable(noise(len(sample_data), seq_length))\n",
        "      noise_sample = noise(len(sample_data), seq_length, noise_features)\n",
        "      #Use this line if generator outputs hidden states: gen_fake_data, (h_g_n,c_g_n) = generator.forward(noise_sample,h_g)\n",
        "      fake_data = generator(noise_sample)\n",
        "      critic_out_fake = discriminator(fake_data)\n",
        "      loss_generator = - critic_out_fake.mean()\n",
        "      #loss_generator = torch.mean(critic_out_fake)\n",
        "      loss_generator.backward() #loss_generator.backward(mone) #https://medium.com/@zhang_yang/the-gradient-argument-in-pytorchs-backward-function-explained-by-examples-68f266950c29\n",
        "      generator_opt.step()\n",
        "        \n",
        "      gradient_p.append(gradient_penalty.item())\n",
        "      G_losses.append(loss_generator.item())\n",
        "      D_losses.append((loss_discriminator).item())\n",
        " \n",
        "    wandb.log({\"criticReal\":critic_out_real, \"criticFake\":critic_out_fake  , \"Critic\": loss_discriminator, \"Generator\": loss_generator, \"GradientPenalty\": gradient_penalty})\n",
        "\n",
        "    with torch.no_grad():\n",
        "        discriminator.eval()\n",
        "        generator.eval()\n",
        "        fake = generator(noise(len(sample_data), seq_length, noise_features)).detach().cpu()\n",
        "        fd = discriminator(fake.to(device)).detach().cpu()                \n",
        "        num_samples = 10\n",
        "        fig = go.Figure()\n",
        "        for i in range(num_samples):\n",
        "            fig.add_trace(go.Scatter(x=np.arange(seq_length), y=fake[i],\n",
        "                mode='lines',\n",
        "                name='s'+str(i)))\n",
        "        wandb.log({'Epoch ' + str(epoch): fig})\n",
        "        \n",
        "        #real:\n",
        "        if epoch == 1:\n",
        "          fig = go.Figure()\n",
        "          for i in range(num_samples):\n",
        "              fig.add_trace(go.Scatter(x=np.arange(seq_length), y=real_data[i],\n",
        "                  mode='lines',\n",
        "                  name='real'))\n",
        "          wandb.log({'Real ': fig})\n",
        "\n",
        "        #####################################################################################################################################\n",
        "        avg_size = 500\n",
        "\n",
        "        rnoise = torch.FloatTensor(avg_size, seq_length).uniform_(-1, 1)\n",
        "        line = torch.zeros(avg_size, seq_length) \n",
        "        for i, s in enumerate(line): \n",
        "          line[i] = s + random.uniform(0.3, 1)\n",
        "        def sineWave1(size = 1, rand=1, amp=0, rad=0, phase=0, offsetY=0):\n",
        "          res = torch.zeros(size, 50)\n",
        "          for t in range(size):\n",
        "            x = np.arange(0,20,0.4)\n",
        "            count = 0\n",
        "            fs = len(x)\n",
        "            if rand:\n",
        "              amp = random.uniform(0.1*1, 0.9*1)\n",
        "              rad = random.uniform(5, 10)\n",
        "              phase = random.uniform(-fs/0.5*np.pi,fs/0.5*np.pi)\n",
        "              offsetY =  0# random.uniform(-1, 1) *1\n",
        "          \n",
        "            y = offsetY + amp*np.sin(((2*np.pi*rad*x)+phase)/fs) \n",
        "            if 0:\n",
        "              for i, s in enumerate(y): \n",
        "                y[i] = s + random.uniform(-0.05, 0.001*i)\n",
        "            y = torch.from_numpy(y).to(dtype=torch.float)\n",
        "            res[t] = y\n",
        "\n",
        "          return res.unsqueeze(2)\n",
        "\n",
        "        sine = sineWave1(avg_size)\n",
        "\n",
        "        fake = generator(noise(avg_size, seq_length, noise_features))\n",
        "        real_out = discriminator(sine)\n",
        "        rnoise_out = discriminator(rnoise)\n",
        "        fake_out = discriminator(fake)\n",
        "        line_out = discriminator(line)\n",
        "\n",
        "        print(f'real input: {real_out.mean():.8f} real std: {real_out.std() }fake input: {fake_out.mean():.8f}  random input: {rnoise_out.mean():.8f} line input: {line_out.mean():.8f}')\n",
        "\n",
        "        data = [real_out.detach().squeeze(1).numpy(), rnoise_out.detach().squeeze(1).numpy(), line_out.detach().squeeze(1).numpy(), fake_out.detach().squeeze(1).numpy()]\n",
        "        group_labels = ['real', 'noise', 'line', 'generator']\n",
        "\n",
        "        # Create distplot with custom bin_size\n",
        "        fig = ff.create_distplot(data, group_labels, bin_size=math.pow(0.5/ math.log(avg_size),2))\n",
        "        #fig.show()\n",
        "        wandb.log({'CriticOut ' + str(epoch): fig})\n",
        "\n",
        "                \n",
        "        #####################################################################################################################################\n",
        "\n",
        "\n",
        "        discriminator.train()\n",
        "        generator.train()\n",
        "\n",
        "\n",
        "        \n",
        "                 \n",
        "\n",
        "        series_list = np.append(series_list,fake[0].numpy().reshape((1,seq_length)),axis=0)\n",
        "\n",
        "        #Saving the parameters of the model to file for each epoch\n",
        "        if epoch % 5 == 0:\n",
        "          saveModel(path, epoch)\n",
        "          saveModel('/content/', 999)\n",
        "          wandb.save('models.tar', base_path='/content')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "#Dumping the errors and mmd evaluations for each training epoch.\n",
        "with open(path+'/generator_losses.txt', 'wb') as fp:\n",
        "    pickle.dump(G_losses, fp)\n",
        "with open(path+'/discriminator_losses.txt', 'wb') as fp:\n",
        "    pickle.dump(D_losses, fp)   \n",
        "with open(path+'/mmd_list.txt', 'wb') as fp:\n",
        "    pickle.dump(mmd_list, fp)\n",
        "\n",
        "#Plotting the error graph\n",
        "plt.plot(G_losses,'-r',label='Generator Error')\n",
        "plt.plot(D_losses, '-b', label = 'Discriminator Error')\n",
        "plt.title('GAN Errors in Training')\n",
        "plt.legend()\n",
        "plt.savefig(path+'/GAN_errors.png')\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "\n",
        "#Plot a figure for each training epoch with the MMD value in the title\n",
        "# i = 0\n",
        "# while i < num_epoch:\n",
        "#   if i%3==0:\n",
        "#     fig, ax = plt.subplots(3,1,constrained_layout=True)\n",
        "#     fig.suptitle(\"Generated fake data\")\n",
        "#   for j in range(0,2):\n",
        "#     ax[j].plot(series_list[i][:])\n",
        "#     ax[j].set_title('Epoch '+str(i)+ ', MMD: %.4f' % (mmd_list[i]))\n",
        "#     i = i+1\n",
        "#   plt.savefig(path+'/Training_Epoch_Samples_MMD_'+str(i)+'.png')\n",
        "#   plt.close(fig) \n",
        "  \n",
        "#Checking the diversity of the samples:\n",
        "generator.eval()\n",
        "test_noise_sample = noise(sample_size, seq_length, noise_features)\n",
        "gen_data= generator.forward(test_noise_sample).detach()\n",
        "\n",
        "plt.title(\"Generated Sine Waves\")\n",
        "plt.plot(gen_data[random.randint(0,sample_size-1)].tolist(),'-b')\n",
        "plt.plot(gen_data[random.randint(0,sample_size-1)].tolist(),'-r')\n",
        "plt.plot(gen_data[random.randint(0,sample_size-1)].tolist(),'-g')\n",
        "plt.plot(gen_data[random.randint(0,sample_size-1)].tolist(),'-', color = 'orange')\n",
        "plt.savefig(path+'/Generated_Data_Sample1.png')\n",
        "plt.close()\n",
        "\n",
        "print('Training Complete!')\n",
        "torch.save({\n",
        "        'generator_state_dict': generator.state_dict(),\n",
        "        'discriminator_state_dict': discriminator.state_dict(),\n",
        "        'optimizerG_state_dict': generator_opt.state_dict(),\n",
        "        'optimizerD_state_dict': discriminator_opt.state_dict()   \n",
        "        }, path + '/modelComplete' + str(trainCounter)+'.tar')\n",
        "print('Model saved in Drive!')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using : cpu\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Models loaded!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5552cfd7af604a7fb2146af434108ed3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=250.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QB4gy8hQ79Nl"
      },
      "source": [
        "saveModel('/content/', 199)\r\n",
        "wandb.save('epoch199.tar', base_path='/content')\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biQxVa_O26p7"
      },
      "source": [
        "num_samples = 9\r\n",
        "num_classes = 40\r\n",
        "df = pd.DataFrame(index=range(num_samples), columns=[str(x) for x in range(num_classes)])\r\n",
        "for i in range(num_samples):\r\n",
        "    df.iloc[i] = torch.randn(1, num_classes).numpy().round(2)\r\n",
        "\r\n",
        "print(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHkJHeAOQrii"
      },
      "source": [
        "# beta 0 -> 0.5\r\n",
        "#     if epoch <20:\r\n",
        "#       lr_d = lr_d * 10\r\n",
        "#       lr_g = lr_g * 10\r\n",
        "#     if epoch == 20:\r\n",
        "#       lr_d = lr_d * 0.1\r\n",
        "#       lr_g = lr_g * 0.1\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpF5kN1O7d1b",
        "scrolled": false
      },
      "source": [
        "import os\n",
        "\n",
        "print('remount storage!')\n",
        "torch.save({\n",
        "        'generator_state_dict': generator.state_dict(),\n",
        "        'discriminator_state_dict': discriminator.state_dict(),\n",
        "        'optimizerG_state_dict': generator_opt.state_dict(),\n",
        "        'optimizerD_state_dict': discriminator_opt.state_dict()   \n",
        "        }, 'wgan2.tar')\n",
        "print('Model saved!')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6srp5M5e8csD"
      },
      "source": [
        "testNoise = noise(sample_size, int(seq_length*1), noise_features)\n",
        "testOut = generator(testNoise)\n",
        "for n in testOut:\n",
        "  plt.plot(n.detach().cpu())\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhIEroKk7d1e",
        "scrolled": false
      },
      "source": [
        "#from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "\n",
        "\n",
        "testNoise = noise(sample_size, int(seq_length*10), noise_features)\n",
        "testOut = generator(testNoise)\n",
        "\n",
        "for n in testOut:\n",
        "    plt.plot(n.detach().cpu())\n",
        "plt.show()\n",
        "\n",
        "plt.show()\n",
        "plt.figure(figsize=(16,10))\n",
        "plt.plot(testOut[0].detach().cpu(), 'black') \n",
        "plt.plot(testOut[0].detach().cpu() , 'bisque')\n",
        "plt.plot(testOut[1].detach().cpu() , 'aquamarine')\n",
        "plt.plot(testOut[2].detach().cpu() , 'lightsteelblue')\n",
        "plt.plot(testOut[3].detach().cpu() , 'lightcoral')\n",
        "plt.plot(testOut[4].detach().cpu() , 'cornsilk')\n",
        "plt.plot(testOut[5].detach().cpu() , 'thistle')\n",
        "plt.plot(testOut[6].detach().cpu() , 'peachpuff')\n",
        "plt.plot(testOut[7].detach().cpu() , 'powderblue')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "r1u =  0 # delta\n",
        "r1l = -0 # delta\n",
        "r2u =  0 # amplitude\n",
        "r2l = -0 # amplitude\n",
        "r3u =  0 # freq (+ amplitude)\n",
        "r3l = -0 # freq (+ amplitude)\n",
        "r4u =  0 # freq (+ amplitude)\n",
        "r4l = -0 # freq (+ amplitude)\n",
        "\n",
        "for b in range(2):\n",
        "  r1 = random.uniform(r1u,r1l)\n",
        "  r2 = random.uniform(r2u,r2l)\n",
        "  r3 = random.uniform(r3u,r3l)    #-> noise_features = 3\n",
        "  r4 = random.uniform(r4u,r4l)\n",
        "\n",
        "  #r4 = random.uniform(-1,1)   #-> noise_features = 4 ...\n",
        "  for i in range(seq_length):\n",
        "    testNoise[b][i][0] = r1  \n",
        "    testNoise[b][i][1] = r2 \n",
        "    testNoise[b][i][2] = r3 \n",
        "    testNoise[b][i][3] = r4\n",
        "    \n",
        "# fig = plt.figure(constrained_layout=True)\n",
        "# ax = fig.add_subplot( projection='3d')  \n",
        "# for b in range(sample_size):\n",
        "#     ax.scatter(testNoise[b][0][0].cpu(), testNoise[b][0][1].cpu(), testNoise[b][0][2].cpu(), marker=\".\")\n",
        "\n",
        "# ax.set_xlabel('Freq')\n",
        "# ax.set_ylabel('Ampl')\n",
        "# ax.set_zlabel('delta')\n",
        "# plt.show()\n",
        "for i in range(seq_length):\n",
        "    testNoise[0][i][0] = r1  \n",
        "    testNoise[0][i][1] = r2 \n",
        "    testNoise[0][i][2] = r3 \n",
        "    testNoise[0][i][3] = r4\n",
        "    testNoise[1][i][0] = r1 - 0.0\n",
        "    testNoise[1][i][1] = r2 - 0.0\n",
        "    testNoise[1][i][2] = r3 + 0.0\n",
        "    testNoise[1][i][3] = r4 + 0.0\n",
        "\n",
        "testOut = generator(testNoise)\n",
        "\n",
        "plt.show()\n",
        "plt.figure(figsize=(16,10))\n",
        "plt.plot(testOut[0].detach().cpu(), 'black') \n",
        "plt.plot(testOut[1].detach().cpu() , 'red')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}